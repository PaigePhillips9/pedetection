{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34dbfb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n",
      "2.8.0\n",
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2\"\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3d6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random as rn\n",
    "import sys\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from tensorflow import keras\n",
    "import random\n",
    "\n",
    "# import config\n",
    "# from pe_logger import PELogger\n",
    "# from plots.plot_results import (save_accuracy_plot, save_loss_plot,\n",
    "#                                 save_pr_curve, save_roc_curve)\n",
    "from inception_resnet_v2_gray import InceptionResNetV2Gray\n",
    "# from training.slice_data_generator import SliceDataGenerator\n",
    "\n",
    "# Set seeding based on Keras documentation\n",
    "np.random.seed(1)\n",
    "rn.seed(2)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# logger = PELogger().get_logger()\n",
    "\n",
    "# CONFIG = config.config()\n",
    "# MODEL_DIR = CONFIG[\"model\"][\"model_dir\"]\n",
    "# PLOT_DIR = CONFIG[\"model\"][\"plot_dir\"]\n",
    "IMAGE_W = 386\n",
    "IMAGE_H = 386\n",
    "ENCODING_DIM = 64\n",
    "FILENAME_COL = \"png_filename\"\n",
    "LABEL_COL = \"label\"\n",
    "FOLD_COL = \"pat_fold\"\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "PRETRAINED_WEIGHTS = \"./pretrained/InceptionResNetV2_NIH15_Px256.h5\"\n",
    "MODEL_DIR = '/home/shared/model_checkpoint_paige/singlescan-3channel/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2cb1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_channels: int) -> keras.models.Model:\n",
    "    \n",
    "    inputs = keras.Input(shape=(IMAGE_W,IMAGE_H,1))\n",
    "    \n",
    "    inception = InceptionResNetV2Gray(\n",
    "                    input_shape=(IMAGE_H, IMAGE_W, 1),\n",
    "                    include_top=False,\n",
    "                    weights='pretrained/InceptionResNetV2_NIH15_Px256.h5',\n",
    "                )\n",
    "    x = inception(inputs)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(inception.output)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    x = keras.layers.Dense(ENCODING_DIM)(x)\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.models.Model(inputs=inception.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_generators(\n",
    "    df,\n",
    "    fold,\n",
    "):\n",
    "\n",
    "    train_df = df[df.fold != fold].reset_index(drop=True)\n",
    "    test_df = df[df.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    train_generator = DataSliceGenerator(train_df, \n",
    "                                   IMAGE_PATH, \n",
    "                                   img_type = IMG_TYPE,\n",
    "                                   verbose=False, \n",
    "                                   n_channels=1, \n",
    "                                   set_type='train',\n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   shuffle=True,\n",
    "                                   dim=386)\n",
    "    \n",
    "    valid_generator = DataSliceGenerator(test_df, \n",
    "                                   IMAGE_PATH, \n",
    "                                   img_type = IMG_TYPE,\n",
    "                                   verbose=False, \n",
    "                                   set_type = 'valid',\n",
    "                                   n_channels=1, \n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   shuffle=False,\n",
    "                                   dim=386)\n",
    "\n",
    "    return train_generator, valid_generator\n",
    "\n",
    "\n",
    "def train(\n",
    "    df: pd.DataFrame,\n",
    "    model_prefix: str,\n",
    "    num_channels: int,\n",
    "    pre_train_top: bool,\n",
    "    fold: int,\n",
    "):\n",
    "    \"\"\"Train a slice based (2D) binary classification model using Inception ResNet V2 backbone.\n",
    "    Best model for given fold will be saved based validation loss.\n",
    "    Args:\n",
    "        df: dataframe object that contains list of images with labels and fold info\n",
    "        image_dir: directory from which training images are loaded from\n",
    "        model_prefix: prefix to use when storing trained models\n",
    "        num_channels: number of input channels to use, 1 = NIH, 2 = ImageNet (RGB)\n",
    "        pre_train_top: flag whether to first train a the classifier part\n",
    "        fold: number indicating cross-validation fold\n",
    "    \"\"\"\n",
    "    model = get_model(1)\n",
    "\n",
    "    train_generator, valid_generator = get_generators(df, fold)\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "    training_histories = []\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "#     os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(MODEL_DIR, f\"{model_prefix}_fold_{fold:02d}.h5\")\n",
    "    check = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    if fold == 0:\n",
    "        model.summary()\n",
    "\n",
    "    hist_full = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        shuffle=False,\n",
    "        validation_data=valid_generator,\n",
    "        callbacks=[check],\n",
    "    )\n",
    "\n",
    "    training_histories.append(pd.DataFrame(hist_full.history))\n",
    "\n",
    "    df_hist = pd.concat(training_histories, axis=0, ignore_index=True, sort=False)\n",
    "    df_hist.to_csv(os.path.join(MODEL_DIR, f\"hist_{model_prefix}_fold_{fold:02d}.csv\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af89bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3529123/1656503385.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_ids = pd.read_csv('all_ids_updated.csv')\n"
     ]
    }
   ],
   "source": [
    "all_ids = pd.read_csv('all_ids_updated.csv')\n",
    "all_ids = all_ids[all_ids.contains_lung == True].sample(frac=1).reset_index(drop=True)\n",
    "all_ids.ycoord = all_ids.ycoord.replace('True', '1.0').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf29cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df = pd.read_csv('folds.csv')\n",
    "all_ids = pd.merge(all_ids, fold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5252d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 12:11:10.011097: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 12:11:10.517637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11470 MB memory:  -> device: 0, name: NVIDIA GeForce GTX TITAN X, pci bus id: 0000:09:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 12:11:33.943706: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2022-12-12 12:11:34.649414: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36/10738 [..............................] - ETA: 2:17:12 - loss: 0.7885 - accuracy: 0.5434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "FOLDS = 10\n",
    "EPOCHS = 3\n",
    "MODEL_DIR = '/home/shared/model_checkpoint_paige/singlescan-3channel/'\n",
    "\n",
    "for fold in range(8, FOLDS):\n",
    "    print(fold)\n",
    "    train(all_ids, 'turku-incepres', 1, True, fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b20863a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21/264 [=>............................] - ETA: 3:09 - loss: 0.3507 - accuracy: 0.8475"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m opt \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m, decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      4\u001b[0m models[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mopt, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_generator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/training.py:1716\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1715\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1716\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1717\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1718\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_generator, valid_generator = get_generators(all_ids, 0)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "models[0].compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "models[0].evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83698325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-paige/turku_aug_funcs.py:3: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n",
      "/home/jupyter-paige/turku_aug_funcs.py:4: DeprecationWarning: Please use `map_coordinates` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import map_coordinates\n"
     ]
    }
   ],
   "source": [
    "import turku_aug_funcs\n",
    "\n",
    "class DataSliceGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\n",
    "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, all_df, image_path, img_type, set_type, n_channels=1, \n",
    "                 batch_size=32, dim=386, num_pos=None, n_classes=2, shuffle=True,\n",
    "                 verbose=False, to_fit=True,\n",
    "                 ):\n",
    "        \"\"\"Initialization\n",
    "        :param list_IDs: list of all 'label' ids to use in the generator\n",
    "        :param labels: list of image labels (file names)\n",
    "        :param image_path: path to images location\n",
    "        :param mask_path: path to masks location\n",
    "        :param to_fit: True to return X and y, False to return X only\n",
    "        :param batch_size: batch size at each iteration\n",
    "        :param dim: tuple indicating image dimension\n",
    "        :param n_channels: number of image channels\n",
    "        :param n_classes: number of output masks\n",
    "        :param shuffle: True to shuffle label indexes after every epoch\n",
    "        \"\"\"\n",
    "        self.image_path = image_path\n",
    "        self.to_fit = to_fit\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.path_dicom = image_path\n",
    "        self.verbose = verbose\n",
    "        self.img_type = img_type\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        self.all_df = all_df\n",
    "        self.set_type = set_type\n",
    "        \n",
    "        if self.set_type == 'test':\n",
    "            self.labels = self.all_df\n",
    "        elif self.set_type == 'valid':\n",
    "            pos = self.all_df[self.all_df.pe_present_on_image == True]\n",
    "            neg = self.all_df[self.all_df.pe_present_on_image == False].sample(n=len(pos))\n",
    "            self.labels = pd.concat([pos,neg]).sample(frac=1).reset_index(drop=True)\n",
    "        elif self.set_type == 'train':\n",
    "            pos = self.all_df[self.all_df.pe_present_on_image ==True]\n",
    "            neg = self.all_df[self.all_df.pe_present_on_image == False].sample(n=len(pos))\n",
    "            self.labels = pd.concat([pos,neg]).sample(frac=1).reset_index(drop=True)\n",
    "        else:\n",
    "            print('Invalid set type, must be test, valid or train')\n",
    "            return False\n",
    "        \n",
    "        self.list_IDs = np.arange(len(self.labels))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.list_IDs)\n",
    "\n",
    "        \n",
    "    def get_df(self):\n",
    "        return self.labels\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        \n",
    "        indexes = self.list_IDs[index * self.batch_size:((index+1) * self.batch_size)]\n",
    "        X = np.zeros([self.batch_size,self.dim,self.dim,1])\n",
    "        y = np.zeros([self.batch_size, 1])\n",
    "        for i in range(0,self.batch_size):\n",
    "            X[i], y[i] = self._load_dicom(indexes[i])\n",
    "            \n",
    "        if self.verbose == True:\n",
    "            fig, ax = plt.subplots(self.batch_size, 1, figsize=[12, 12*(self.batch_size/2)])\n",
    "            for i in range(self.batch_size):\n",
    "                ax[i].imshow(X[i])\n",
    "                ax[i].axis('off')\n",
    "        \n",
    "        X = X/255\n",
    "            \n",
    "        if self.to_fit:\n",
    "            return (X, y)\n",
    "        else:\n",
    "            return (X)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        if self.set_type == 'train':\n",
    "            pos = self.all_df[self.all_df.pe_present_on_image ==True]\n",
    "            neg = self.all_df[self.all_df.pe_present_on_image == False].sample(n=len(pos)*3)\n",
    "            self.labels = pd.concat([pos,pos,pos,neg]).sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "        self.list_IDs = np.arange(len(self.labels))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.list_IDs)\n",
    "\n",
    "            \n",
    "    def _load_dicom(self, index):\n",
    "        slice = self.labels.iloc[index] \n",
    "\n",
    "        frame = cv2.imread(self.image_path+slice.StudyInstanceUID + '_'+ slice.SeriesInstanceUID\n",
    "                      + '_' + slice.SOPInstanceUID +'.png')\n",
    "        frame = frame[:,:,self.img_type]\n",
    "        \n",
    "#         frame = np.reshape(frame, (256,256,1))      \n",
    "        \n",
    "        if self.set_type == 'train':\n",
    "            trans = random.sample(range(0,5),random.randint(0,5))\n",
    "            if 0 in trans:\n",
    "                frame = turku_aug_funcs.blur(frame)\n",
    "            if 1 in trans:\n",
    "                zoom = random.randint(0,2)\n",
    "                if zoom == 0:\n",
    "                    frame = turku_aug_funcs.zoom_1_05(frame)\n",
    "                if zoom == 1:\n",
    "                    frame = turku_aug_funcs.zoom_1_075(frame)\n",
    "                if zoom == 2:\n",
    "                    frame = turku_aug_funcs.zoom_1_15(frame)\n",
    "\n",
    "            if 2 in trans:\n",
    "                rot = random.randint(0,3)\n",
    "                if rot == 0:\n",
    "                    frame = turku_aug_funcs.rotate_3(frame)\n",
    "                if rot == 1:\n",
    "                    frame = turku_aug_funcs.rotate_m3(frame)\n",
    "                if rot == 2:\n",
    "                    frame = turku_aug_funcs.rotate_5(frame)\n",
    "                if rot == 3:\n",
    "                    frame = turku_aug_funcs.rotate_m5(frame)\n",
    "\n",
    "            if 3 in trans:\n",
    "                frame = np.reshape(frame, (1,256,256))\n",
    "                frame = turku_aug_funcs.gaussian_noise(frame)\n",
    "                frame = frame.squeeze()\n",
    "\n",
    "            if 4 in trans:\n",
    "                tx = random.randint(0,6)\n",
    "                if tx == 0:\n",
    "                    frame = turku_aug_funcs.tr_x10(frame)\n",
    "                if tx == 1:\n",
    "                    frame = turku_aug_funcs.tr_x15(frame)\n",
    "                if tx == 2:\n",
    "                    frame = turku_aug_funcs.tr_x20(frame)\n",
    "                if tx == 3:\n",
    "                    frame = turku_aug_funcs.tr_xm10(frame)\n",
    "                if tx == 4:\n",
    "                    frame = turku_aug_funcs.tr_xm15(frame)\n",
    "                if tx == 5:\n",
    "                    frame = turku_aug_funcs.tr_xm20(frame)\n",
    "                tx = random.randint(0,6)\n",
    "                if tx == 0:\n",
    "                    frame = turku_aug_funcs.tr_y10(frame)\n",
    "                if tx == 1:\n",
    "                    frame = turku_aug_funcs.tr_y15(frame)\n",
    "                if tx == 2:\n",
    "                    frame = turku_aug_funcs.tr_y20(frame)\n",
    "                if tx == 3:\n",
    "                    frame = turku_aug_funcs.tr_ym10(frame)\n",
    "                if tx == 4:\n",
    "                    frame = turku_aug_funcs.tr_ym15(frame)\n",
    "                if tx == 5:\n",
    "                    frame = turku_aug_funcs.tr_ym20(frame)\n",
    "        frame = cv2.resize(frame, (386,386))\n",
    "        frame = np.reshape(frame, (386,386,1))\n",
    "        \n",
    "        if self.verbose == True:\n",
    "            print(np.shape(frame))\n",
    "            plt.imshow(frame)\n",
    "            plt.show()\n",
    "\n",
    "        frame = frame[None, ...]\n",
    "        y = np.array([int(slice.pe_present_on_image)])\n",
    "        y = y[None, ...]\n",
    "        \n",
    "        return frame, y\n",
    "\n",
    "CROPPED = 0\n",
    "MASKED = 1\n",
    "ORIGINAL = 2\n",
    "\n",
    "IMG_TYPE = MASKED\n",
    "IMAGE_PATH = '/home/shared/nps/imgs/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99634fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2129605/1642990385.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_ids = pd.read_csv('all_ids_updated.csv')\n"
     ]
    }
   ],
   "source": [
    "all_ids = pd.read_csv('all_ids_updated.csv')\n",
    "all_ids = all_ids[all_ids.contains_lung == True].sample(frac=1).reset_index(drop=True)\n",
    "all_ids.ycoord = all_ids.ycoord.replace('True', '1.0').astype('float')\n",
    "\n",
    "all_ids_small = all_ids.drop(columns=['negative_exam_for_pe', 'qa_motion',\n",
    "       'qa_contrast', 'flow_artifact', 'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1',\n",
    "       'leftsided_pe', 'chronic_pe', 'true_filling_defect_not_pe',\n",
    "       'rightsided_pe', 'acute_and_chronic_pe', 'central_pe', 'indeterminate',\n",
    "       'contains_lung'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89e6a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a764410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_345789/585394138.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_ids = pd.read_csv('all_ids_updated.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6805\n"
     ]
    }
   ],
   "source": [
    "all_ids = pd.read_csv('all_ids_updated.csv')\n",
    "all_ids.ycoord = all_ids.ycoord.replace('True', '1.0').astype('float')\n",
    "train_ids = pd.read_csv('train_df_upd.csv').drop(columns='Unnamed: 0')\n",
    "test_ids = pd.read_csv('test_df_upd.csv').drop(columns='Unnamed: 0')\n",
    "val_ids = pd.read_csv('val_df_upd.csv').drop(columns='Unnamed: 0')\n",
    "\n",
    "import os \n",
    "lisdir = os.listdir('/home/shared/nps/turku_nps/')\n",
    "print(len(lisdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e629b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "model_partials = []\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "for i in range(0,10):\n",
    "    models.append(get_model(1))\n",
    "    models[i].compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    models[i].load_weights(MODEL_DIR + 'turku-incepres_fold_0'+ str(i) +'.h5')\n",
    "    model_partials.append(keras.models.Model(inputs=models[i].input, outputs=[models[i].layers[-2].output]))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c12e9fa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(exam)\u001b[38;5;241m/\u001b[39mBATCH_SIZE)):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,MAX):\n\u001b[0;32m---> 34\u001b[0m         feats[k, j\u001b[38;5;241m*\u001b[39mBATCH_SIZE:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mBATCH_SIZE] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_partials\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         results[k, j\u001b[38;5;241m*\u001b[39mBATCH_SIZE:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mBATCH_SIZE] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(models[k](x_test[j\u001b[38;5;241m*\u001b[39mBATCH_SIZE:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mBATCH_SIZE]))\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(exam)\u001b[38;5;241m%\u001b[39mBATCH_SIZE \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "\n",
    "unique_ids = all_ids.StudyInstanceUID.unique()\n",
    "\n",
    "IMG_TYPE = MASKED\n",
    "IMAGE_PATH = '/home/shared/nps/imgs/'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "MAX = 2\n",
    "\n",
    "for i in range(0,len(unique_ids)):\n",
    "    exam_id = unique_ids[i]\n",
    "    exam = all_ids[all_ids.StudyInstanceUID == exam_id]\n",
    "    exam = exam.sort_values(by='ycoord')\n",
    "    exam_generator = DataSliceGenerator(exam, \n",
    "                                   IMAGE_PATH, \n",
    "                                   img_type = IMG_TYPE,\n",
    "                                   verbose=False, \n",
    "                                   set_type = 'test',\n",
    "                                   shuffle=False,\n",
    "                                   n_channels=1, \n",
    "                                   batch_size=1,\n",
    "                                   dim=386)\n",
    "    \n",
    "    x_test = np.zeros([len(exam),386,386,1])\n",
    "    for j in range(0,len(exam)):\n",
    "        x_test[j],_ = exam_generator.__getitem__(j)\n",
    "           \n",
    "    feats = np.zeros([MAX, len(exam),64])\n",
    "    results = np.zeros([MAX,len(exam),1])\n",
    "    for j in range(int(len(exam)/BATCH_SIZE)):\n",
    "        for k in range(0,MAX):\n",
    "            feats[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(model_partials[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "            results[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(models[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "    if len(exam)%BATCH_SIZE != 0:\n",
    "        for k in range(0,MAX):\n",
    "            feats[k, (j+1)*BATCH_SIZE:] = np.array(model_partials[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "            results[k, (j+1)*BATCH_SIZE:] = np.array(models[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "        \n",
    "    for k in range(0,MAX):\n",
    "        exam['features'] = feats[k].tolist()\n",
    "        exam['preds'] = results[k].tolist()\n",
    "        np.save('/home/shared/nps/turku_0'+ str(k)+ '/' + exam_id, exam.to_dict(orient='records'))\n",
    "\n",
    "    if i %10 == 0:\n",
    "        print(i, 'time is: ', datetime.datetime.now())\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec0bcac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df = pd.read_csv('folds.csv')\n",
    "all_ids = pd.merge(all_ids, fold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "042e3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = all_ids[(all_ids.negative_exam_for_pe == False) & (all_ids.fold == 0)].StudyInstanceUID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92020a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3f28b9d32596', 'c8aeafba5334', '7e209fbfc30a', 'ca9fafa5d5e7',\n",
       "       '216400e63bb3', 'a711e3f632d0', '5a649181c295', '018b5097a129',\n",
       "       '6fab99baa593', '1c0a60a5bf38', 'c593fa6a480b', 'bcd48aa10710',\n",
       "       '7ebfc5fe0caf', 'ec36deb204d3', 'af0fa891991a', '757535dda5f4',\n",
       "       '5120108a1940', '90bca49335fc', 'b0385ef57697', 'ac9350709953',\n",
       "       '2988af19b941', '25b3b3270108', '6b4009e175a0', 'd40cdd117143',\n",
       "       '93072a8bf3c4', 'cd0f7d6be318', '8aad4d650a05', '665099cd6228',\n",
       "       '5a8c9a50239b', '7a234b6e6eb3', '94a5a995efab', '242ef334aa07',\n",
       "       '4658f71f3692', '8036479efea4', '6ad821b36eda', '671a05e18984',\n",
       "       '0cd398286a7b', '9c5ac31b9dd6', '37a9543f187f', 'f5029e76e793',\n",
       "       '90cd80093e37', 'a813eaeaf84e', '8f9c50b17d2f', '759a5963508b',\n",
       "       '7b181499758c', '5ea1e4378c10', '2008f14c56d7', '7826ae6f1218',\n",
       "       'f037e7310f8f', 'f52f636ef7e1', '62e8b6cf4f54', '7bcb8de6305c',\n",
       "       '0e81dd7637d7', '9990b97f784e', 'eb835e5ea3f3', '21b615e2b5fb',\n",
       "       '3acbb4e48651', '58e9e7e51f10', 'cd3758645828', '02e66085f1b1',\n",
       "       '6df74ad90858', '26f82c3c8072', '41bdf8d7cffe', 'e05a296654f2',\n",
       "       'ebc59444c282', '39cc04c534ae', '3889f25943ba', 'acab4b22706f',\n",
       "       'cd3a45ab948a', 'afb7251797b0', 'af805a561426', 'b3b257835d70',\n",
       "       'eb51866151eb', '8dab7007a628', 'f90d25ca8c89', 'ae463fa7ac85',\n",
       "       '3860c608cda6', '6834b6d40d27', '86dca67116dd', '85a4d75a3d3c',\n",
       "       'c307b9c85c68', '5a83a90b867b', '732c31688ffe', '91b94aac56ce',\n",
       "       '15422ea8ba8f', 'cdc4ce03759e', 'bb2c3733ee07', '0c2a250bc517',\n",
       "       '8ed86f44355b', 'f3d7db1ccba2', '03e660e025b3', '4a87fffc0147',\n",
       "       '7a0d49c3a2e8', '80ca269f2c33', '6897fa9de148', 'ada5e3d4ba29',\n",
       "       '0bc9df66d839', 'd5983148dc12', 'a9c9227e5f8d', '2e42719153f3',\n",
       "       'eb466cd02768', '3a38e12fc7eb', '33cf357b5cf7', 'd967ac194e59',\n",
       "       '3cae6b4fe93a', 'b6e40f432824', '12e365c9fb9d', 'b905931159ec',\n",
       "       '28e2b8e90680', '050656e839da', 'f37f094554f3', '70d2295e765a',\n",
       "       '36e4f659feb4', '8b1e0be12d8e', 'a5ca028b24d6', '2aabea825334',\n",
       "       'c281eca04485', 'f430d09742db', 'a1b136fa8d31', 'de2c2d848ea6',\n",
       "       '7e3b2f344b77', 'a91d0044beb1', '5233a0c01815', '609f7ad093a7',\n",
       "       'e01969cd78e4', 'c8d65acf79eb', '8db8c571c33a', '150dca1803c3',\n",
       "       '162e691d7e8f', '6e2cb2e6330a', '05ca741b1135', '5306ae767461',\n",
       "       '4c5397c29ca0', 'b11a626b05e3', '86765ed0739f', '051b3092bef5',\n",
       "       '0c1214d5593d', '0954c99930f6', 'a30dcb7e30d7', '2bb4fdce19d1',\n",
       "       'dd3fce957cfc', '099e40f80b1a', 'a4dd0ecf472e', 'c2551418aecc',\n",
       "       '34114543b210', '5eb4dc507d64', '4e2fa990252f', '31d8193f16c2',\n",
       "       '57756f1d5e74', '2b902586a205', '7a197a7b513e', 'b894274e15d6',\n",
       "       '155c4d3b834b', '4b0110171dbc', '1470a7c0a009', 'f304a939bbc7',\n",
       "       '29387e715bd9', '25e491291085', '8c24fd05907c', '9ac35ede8178',\n",
       "       '50f3a6ecbc04', '47c37e0f514d', 'd5d5247d293b', 'a7aaed73c99d',\n",
       "       '0d282fe7068c', 'b09eaad2e75a', '750b6e3a8d3c', 'bfd428ecfa56',\n",
       "       'ae7584e285a1', '95cc4be08d5b', '4f633567e835', '6e2239c42e9b',\n",
       "       '8411a90a9cf3', '4776d4bdc72d', '08fd7f06da89', 'cf66a790fb41',\n",
       "       'b5e892be48c6', '00c07cd8129d', 'ceff046d0144', '2fe10802e6ce',\n",
       "       '7f58498baa8b', 'fc078a8f9ccc', 'cbb450abfe0e', '30d0ae8fa390',\n",
       "       '6158a10eeb26', '40577c28deb3', '527611d51699', 'dd90fd727d7b',\n",
       "       '2ec0ba1236ba', '8660c476ad4e', '12f9fc9a09ff', 'e7f9a2c2dc69',\n",
       "       '3feac0ec0f85', '27bf09312237', 'a54746e65833', '15983c8b81cd',\n",
       "       '26b59b600bb4', 'dc44c1a5eb1c', '6c5891334693', 'e669965b77e4',\n",
       "       '43b651dbc5e1', '2e1ae43b78fe', '2ab547d2ca40', '2a2a5384f454',\n",
       "       '528b58c00f58', '73864f06e96e', '54115bf48244', 'c5c9674355f3',\n",
       "       '74a04c47cd6c', 'c628af95d291', '666b9ad4f63b', '137939b0ef61',\n",
       "       'de584b2d152b'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51377f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 time is:  2022-12-12 20:01:20.798340\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "\n",
    "# unique_ids = all_ids.StudyInstanceUID.unique()\n",
    "unique_ids = all_ids[(all_ids.negative_exam_for_pe == False) & (all_ids.fold == 0)].StudyInstanceUID.unique()\n",
    "\n",
    "unique_ids = ['b11a626b05e3']\n",
    "IMG_TYPE = CROPPED\n",
    "IMAGE_PATH = '/home/shared/nps/imgs/'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "MAX = 1\n",
    "\n",
    "for i in range(0,len(unique_ids)):\n",
    "    exam_id = unique_ids[i]\n",
    "    exam = all_ids[all_ids.StudyInstanceUID == exam_id]\n",
    "    exam = exam.sort_values(by='ycoord')\n",
    "    exam_generator = DataSliceGenerator(exam, IMAGE_PATH, img_type = IMG_TYPE,\n",
    "                                        verbose=False, n_channels=1, \n",
    "                                        set_type='test', batch_size=1,\n",
    "                                        shuffle=False, dim=386)\n",
    "\n",
    "    x_test = np.zeros([len(exam),386,386,1])\n",
    "    for j in range(0,len(exam)):\n",
    "        x_test[j],_ = exam_generator.__getitem__(j)\n",
    "           \n",
    "    feats = np.zeros([MAX, len(exam),64])\n",
    "    results = np.zeros([MAX,len(exam),1])\n",
    "    for j in range(int(len(exam)/BATCH_SIZE)):\n",
    "        for k in range(0,MAX):\n",
    "            feats[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(model_partials[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "            results[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(models[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "    if len(exam)%BATCH_SIZE != 0:\n",
    "        for k in range(0,MAX):\n",
    "            feats[k, (j+1)*BATCH_SIZE:] = np.array(model_partials[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "            results[k, (j+1)*BATCH_SIZE:] = np.array(models[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "        \n",
    "    for k in range(0,MAX):\n",
    "        exam['features'] = feats[k].tolist()\n",
    "        exam['preds'] = results[k].tolist()\n",
    "#         np.save('/home/shared/nps/turku_check_'+ str(k)+ '/' + exam_id, exam.to_dict(orient='records'))\n",
    "\n",
    "    if i %10 == 0:\n",
    "        print(i, 'time is: ', datetime.datetime.now())\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7ffa5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: preds, dtype: object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam[exam.pe_present_on_image == True].preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30a5c0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7900773358817857"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(exam[exam.pe_present_on_image == True].preds.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9aa9d9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c8aeafba5334'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.StudyInstanceUID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "0 time is:  2022-12-03 19:24:03.967259\n",
      "10 time is:  2022-12-03 19:27:50.867344\n",
      "20 time is:  2022-12-03 19:31:44.469551\n",
      "30 time is:  2022-12-03 19:35:40.729277\n",
      "40 time is:  2022-12-03 19:39:43.032734\n",
      "50 time is:  2022-12-03 19:42:57.965260\n",
      "60 time is:  2022-12-03 19:47:21.485160\n",
      "70 time is:  2022-12-03 19:51:38.390659\n",
      "80 time is:  2022-12-03 19:55:45.362907\n",
      "90 time is:  2022-12-03 19:59:13.773276\n",
      "100 time is:  2022-12-03 20:02:33.682846\n",
      "110 time is:  2022-12-03 20:05:58.601448\n",
      "120 time is:  2022-12-03 20:10:11.698824\n",
      "130 time is:  2022-12-03 20:14:04.185687\n",
      "140 time is:  2022-12-03 20:17:38.397889\n",
      "150 time is:  2022-12-03 20:20:59.264195\n",
      "160 time is:  2022-12-03 20:24:37.974125\n",
      "170 time is:  2022-12-03 20:28:19.174748\n",
      "180 time is:  2022-12-03 20:32:04.380271\n",
      "190 time is:  2022-12-03 20:35:44.163386\n",
      "200 time is:  2022-12-03 20:39:27.069022\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "model_partials = []\n",
    "\n",
    "MIN = 2\n",
    "MAX = 5\n",
    "for i in range(MIN,MAX):\n",
    "    models.append(get_model(1))\n",
    "    models[i-MIN].load_weights(MODEL_DIR + 'turku-incepres_fold_0'+ str(i) +'.h5')\n",
    "    model_partials.append(keras.models.Model(inputs=models[i-MIN].input, outputs=[models[i-MIN].layers[-2].output]))\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "unique_ids = all_ids.StudyInstanceUID.unique()\n",
    "\n",
    "IMG_TYPE = MASKED\n",
    "IMAGE_PATH = '/home/shared/nps/imgs/'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for i in range(0,len(unique_ids)):\n",
    "    exam_id = unique_ids[i]\n",
    "    exam = all_ids[all_ids.StudyInstanceUID == exam_id]\n",
    "    exam = exam.sort_values(by='ycoord')\n",
    "    exam_generator = DataSliceGenerator(exam, \n",
    "                                   IMAGE_PATH, \n",
    "                                   img_type = IMG_TYPE,\n",
    "                                   verbose=False, \n",
    "                                   set_type = 'test',\n",
    "                                   shuffle=False,\n",
    "                                   n_channels=1, \n",
    "                                   batch_size=1,\n",
    "                                   dim=386)\n",
    "    \n",
    "    x_test = np.zeros([len(exam),386,386,1])\n",
    "    for j in range(0,len(exam)):\n",
    "        x_test[j],_ = exam_generator.__getitem__(j)\n",
    "           \n",
    "    feats = np.zeros([MAX-MIN, len(exam),64])\n",
    "    results = np.zeros([MAX-MIN,len(exam),1])\n",
    "    for j in range(int(len(exam)/BATCH_SIZE)):\n",
    "        for k in range(0,MAX-MIN):\n",
    "            feats[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(model_partials[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "            results[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(models[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "    if len(exam)%BATCH_SIZE != 0:\n",
    "        for k in range(0,MAX-MIN):\n",
    "            feats[k, (j+1)*BATCH_SIZE:] = np.array(model_partials[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "            results[k, (j+1)*BATCH_SIZE:] = np.array(models[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "        \n",
    "    for k in range(MIN,MAX):\n",
    "        exam['features'] = feats[k-MIN].tolist()\n",
    "        exam['preds'] = results[k-MIN].tolist()\n",
    "        np.save('/home/shared/nps/turku_0'+ str(k)+ '/' + exam_id, exam.to_dict(orient='records'))\n",
    "\n",
    "    if i %10 == 0:\n",
    "        print(i, 'time is: ', datetime.datetime.now())\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45b6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "0 time is:  2022-12-09 12:24:47.145020\n",
      "10 time is:  2022-12-09 12:27:24.724880\n",
      "20 time is:  2022-12-09 12:30:35.246488\n",
      "30 time is:  2022-12-09 12:33:18.597317\n",
      "40 time is:  2022-12-09 12:36:05.888092\n",
      "50 time is:  2022-12-09 12:38:48.759846\n",
      "60 time is:  2022-12-09 12:41:11.002942\n",
      "70 time is:  2022-12-09 12:43:44.725570\n",
      "80 time is:  2022-12-09 12:46:37.530960\n",
      "90 time is:  2022-12-09 12:49:10.356916\n",
      "100 time is:  2022-12-09 12:52:03.481524\n",
      "110 time is:  2022-12-09 12:54:33.519392\n",
      "120 time is:  2022-12-09 12:57:16.823327\n",
      "130 time is:  2022-12-09 12:59:49.320302\n",
      "140 time is:  2022-12-09 13:02:13.275386\n",
      "150 time is:  2022-12-09 13:04:19.735304\n",
      "160 time is:  2022-12-09 13:06:57.020183\n",
      "170 time is:  2022-12-09 13:09:13.414922\n",
      "180 time is:  2022-12-09 13:11:51.563823\n",
      "190 time is:  2022-12-09 13:14:15.006973\n",
      "200 time is:  2022-12-09 13:16:29.552263\n",
      "210 time is:  2022-12-09 13:19:04.956429\n",
      "220 time is:  2022-12-09 13:21:44.975000\n",
      "230 time is:  2022-12-09 13:24:44.834540\n",
      "240 time is:  2022-12-09 13:27:29.644256\n",
      "250 time is:  2022-12-09 13:29:57.943270\n",
      "260 time is:  2022-12-09 13:32:26.833515\n",
      "270 time is:  2022-12-09 13:34:41.189759\n",
      "280 time is:  2022-12-09 13:37:06.515333\n",
      "290 time is:  2022-12-09 13:39:12.668524\n",
      "300 time is:  2022-12-09 13:41:57.304719\n",
      "310 time is:  2022-12-09 13:44:31.825727\n",
      "320 time is:  2022-12-09 13:46:50.937257\n",
      "330 time is:  2022-12-09 13:48:55.588870\n",
      "340 time is:  2022-12-09 13:51:57.115015\n",
      "350 time is:  2022-12-09 13:54:17.437641\n",
      "360 time is:  2022-12-09 13:56:43.598676\n",
      "370 time is:  2022-12-09 13:59:10.004332\n",
      "380 time is:  2022-12-09 14:01:40.810319\n",
      "390 time is:  2022-12-09 14:04:08.379265\n",
      "400 time is:  2022-12-09 14:06:24.789646\n",
      "410 time is:  2022-12-09 14:09:08.721783\n",
      "420 time is:  2022-12-09 14:11:40.438023\n",
      "430 time is:  2022-12-09 14:14:16.530084\n",
      "440 time is:  2022-12-09 14:16:46.807776\n",
      "450 time is:  2022-12-09 14:19:08.637241\n",
      "460 time is:  2022-12-09 14:21:23.905854\n",
      "470 time is:  2022-12-09 14:24:13.362952\n",
      "480 time is:  2022-12-09 14:26:27.867132\n",
      "490 time is:  2022-12-09 14:28:47.272446\n",
      "500 time is:  2022-12-09 14:31:15.015496\n",
      "510 time is:  2022-12-09 14:34:05.513886\n",
      "520 time is:  2022-12-09 14:36:57.017735\n",
      "530 time is:  2022-12-09 14:39:27.681940\n",
      "540 time is:  2022-12-09 14:41:52.922252\n",
      "550 time is:  2022-12-09 14:44:19.994707\n",
      "560 time is:  2022-12-09 14:46:40.498356\n",
      "570 time is:  2022-12-09 14:48:52.952549\n",
      "580 time is:  2022-12-09 14:51:30.738801\n",
      "590 time is:  2022-12-09 14:54:05.463856\n",
      "600 time is:  2022-12-09 14:56:19.195990\n",
      "610 time is:  2022-12-09 14:59:00.191978\n",
      "620 time is:  2022-12-09 15:01:16.052819\n",
      "630 time is:  2022-12-09 15:03:54.714740\n",
      "640 time is:  2022-12-09 15:06:13.491178\n",
      "650 time is:  2022-12-09 15:08:49.395320\n",
      "660 time is:  2022-12-09 15:11:19.733687\n",
      "670 time is:  2022-12-09 15:13:53.025254\n",
      "680 time is:  2022-12-09 15:16:49.809618\n",
      "690 time is:  2022-12-09 15:19:17.891690\n",
      "700 time is:  2022-12-09 15:21:49.976669\n",
      "710 time is:  2022-12-09 15:24:09.318255\n",
      "720 time is:  2022-12-09 15:27:08.241073\n",
      "730 time is:  2022-12-09 15:29:40.398895\n",
      "740 time is:  2022-12-09 15:32:06.498229\n",
      "750 time is:  2022-12-09 15:34:48.385726\n",
      "760 time is:  2022-12-09 15:37:50.701803\n",
      "770 time is:  2022-12-09 15:40:20.344525\n",
      "780 time is:  2022-12-09 15:42:46.317224\n",
      "790 time is:  2022-12-09 15:45:21.749857\n",
      "800 time is:  2022-12-09 15:47:46.433175\n",
      "810 time is:  2022-12-09 15:50:10.699908\n",
      "820 time is:  2022-12-09 15:52:22.839594\n",
      "830 time is:  2022-12-09 15:54:31.626253\n",
      "840 time is:  2022-12-09 15:56:59.374065\n",
      "850 time is:  2022-12-09 15:59:47.211299\n",
      "860 time is:  2022-12-09 16:01:55.273821\n",
      "870 time is:  2022-12-09 16:04:22.711486\n",
      "880 time is:  2022-12-09 16:06:41.616354\n",
      "890 time is:  2022-12-09 16:09:06.822227\n",
      "900 time is:  2022-12-09 16:11:36.878522\n",
      "910 time is:  2022-12-09 16:13:53.731143\n",
      "920 time is:  2022-12-09 16:16:11.915585\n",
      "930 time is:  2022-12-09 16:18:42.922757\n",
      "940 time is:  2022-12-09 16:21:32.484643\n",
      "950 time is:  2022-12-09 16:24:16.666614\n",
      "960 time is:  2022-12-09 16:26:44.566687\n",
      "970 time is:  2022-12-09 16:29:10.974137\n",
      "980 time is:  2022-12-09 16:31:28.705467\n",
      "990 time is:  2022-12-09 16:33:56.261750\n",
      "1000 time is:  2022-12-09 16:36:16.973085\n",
      "1010 time is:  2022-12-09 16:38:41.668571\n",
      "1020 time is:  2022-12-09 16:41:30.271773\n",
      "1030 time is:  2022-12-09 16:43:53.631543\n",
      "1040 time is:  2022-12-09 16:46:39.045023\n",
      "1050 time is:  2022-12-09 16:49:22.455616\n",
      "1060 time is:  2022-12-09 16:51:52.699809\n",
      "1070 time is:  2022-12-09 16:54:07.674340\n",
      "1080 time is:  2022-12-09 16:56:38.193078\n",
      "1090 time is:  2022-12-09 16:59:48.811422\n",
      "1100 time is:  2022-12-09 17:02:30.608622\n",
      "1110 time is:  2022-12-09 17:05:02.914232\n",
      "1120 time is:  2022-12-09 17:07:17.308975\n",
      "1130 time is:  2022-12-09 17:09:48.792848\n",
      "1140 time is:  2022-12-09 17:12:29.000033\n",
      "1150 time is:  2022-12-09 17:14:54.301868\n",
      "1160 time is:  2022-12-09 17:17:23.461279\n",
      "1170 time is:  2022-12-09 17:19:40.637654\n",
      "1180 time is:  2022-12-09 17:21:49.145505\n",
      "1190 time is:  2022-12-09 17:24:22.835321\n",
      "1200 time is:  2022-12-09 17:27:05.752320\n",
      "1210 time is:  2022-12-09 17:29:31.374579\n",
      "1220 time is:  2022-12-09 17:32:01.719515\n",
      "1230 time is:  2022-12-09 17:34:34.321298\n",
      "1240 time is:  2022-12-09 17:37:04.768646\n",
      "1250 time is:  2022-12-09 17:39:46.194670\n",
      "1260 time is:  2022-12-09 17:42:28.407392\n",
      "1270 time is:  2022-12-09 17:44:54.680872\n",
      "1280 time is:  2022-12-09 17:47:34.950099\n",
      "1290 time is:  2022-12-09 17:50:40.398755\n",
      "1300 time is:  2022-12-09 17:53:00.774895\n",
      "1310 time is:  2022-12-09 17:55:33.049005\n",
      "1320 time is:  2022-12-09 17:57:50.706639\n",
      "1330 time is:  2022-12-09 18:00:21.998165\n",
      "1340 time is:  2022-12-09 18:02:38.501489\n",
      "1350 time is:  2022-12-09 18:05:16.345642\n",
      "1360 time is:  2022-12-09 18:07:59.249517\n",
      "1370 time is:  2022-12-09 18:10:26.607376\n",
      "1380 time is:  2022-12-09 18:12:55.519218\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "    \n",
    "unique_ids = all_ids.StudyInstanceUID.unique()\n",
    "\n",
    "IMG_TYPE = MASKED\n",
    "IMAGE_PATH = '/home/shared/nps/imgs/'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for i in range(0,len(unique_ids)):\n",
    "    exam_id = unique_ids[i]\n",
    "    exam = all_ids[all_ids.StudyInstanceUID == exam_id]\n",
    "    exam = exam.sort_values(by='ycoord')\n",
    "    exam_generator = DataSliceGenerator(exam, IMAGE_PATH, img_type = IMG_TYPE,\n",
    "                                        verbose=False, n_channels=1, \n",
    "                                        set_type='test', batch_size=1,\n",
    "                                        shuffle=False, dim=386)\n",
    "    \n",
    "    x_test = np.zeros([len(exam),386,386,1])\n",
    "    for j in range(0,len(exam)):\n",
    "        x_test[j],_ = exam_generator.__getitem__(j)\n",
    "           \n",
    "    feats = np.zeros([MAX-MIN, len(exam),64])\n",
    "    results = np.zeros([MAX-MIN,len(exam),1])\n",
    "    for j in range(int(len(exam)/BATCH_SIZE)):\n",
    "        for k in range(0,MAX-MIN):\n",
    "            feats[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(model_partials[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "            results[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(models[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "    if len(exam)%BATCH_SIZE != 0:\n",
    "        for k in range(0,MAX-MIN):\n",
    "            feats[k, (j+1)*BATCH_SIZE:] = np.array(model_partials[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "            results[k, (j+1)*BATCH_SIZE:] = np.array(models[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "        \n",
    "    for k in range(MIN,MAX):\n",
    "        exam['features'] = feats[k-MIN].tolist()\n",
    "        exam['preds'] = results[k-MIN].tolist()\n",
    "        np.save('/home/shared/nps/turku_0'+ str(k)+ '/' + exam_id, exam.to_dict(orient='records'))\n",
    "\n",
    "    if i %10 == 0:\n",
    "        print(i, 'time is: ', datetime.datetime.now())\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93f0618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3530190/1903193064.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_ids = pd.read_csv('test_ids.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3530190/1903193064.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  files.SOPInstanceUID = files.SOPInstanceUID.str.replace('.png','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146840 106463\n",
      "106463\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = '/home/shared/test/imgs/'\n",
    "\n",
    "all_ids = pd.read_csv('test_ids.csv')\n",
    "all_ids = all_ids[all_ids.ycoord != 'ERROR']\n",
    "all_ids.ycoord = all_ids.ycoord.astype('float')\n",
    "\n",
    "lisdir = os.listdir(IMAGE_PATH)\n",
    "\n",
    "files = pd.DataFrame({'file_name':lisdir})\n",
    "print(len(files))\n",
    "\n",
    "files['cols'] = files.file_name.str.split('_')\n",
    "files[['StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID']] = files.cols.tolist()\n",
    "files.SOPInstanceUID = files.SOPInstanceUID.str.replace('.png','')\n",
    "files = files.drop(columns='cols')\n",
    "\n",
    "print(len(all_ids), len(files))\n",
    "all_ids = pd.merge(all_ids, files)\n",
    "print(len(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84a9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids['pe_present_on_image'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b70c3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "model_partials = []\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "for i in range(0,10):\n",
    "    models.append(get_model(1))\n",
    "    models[i].compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    models[i].load_weights(MODEL_DIR + 'turku-incepres_fold_0'+ str(i) +'.h5')\n",
    "    model_partials.append(keras.models.Model(inputs=models[i].input, outputs=[models[i].layers[-2].output]))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f4737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 time is:  2023-01-17 12:02:10.116863\n",
      "10 time is:  2023-01-17 12:07:52.328087\n",
      "20 time is:  2023-01-17 12:13:42.117829\n",
      "30 time is:  2023-01-17 12:19:48.309585\n",
      "40 time is:  2023-01-17 12:25:00.987625\n",
      "50 time is:  2023-01-17 12:31:58.807176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,MAX\u001b[38;5;241m-\u001b[39mMIN):\n\u001b[1;32m     30\u001b[0m         feats[k, j\u001b[38;5;241m*\u001b[39mBATCH_SIZE:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mBATCH_SIZE] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(model_partials[k](x_test[j\u001b[38;5;241m*\u001b[39mBATCH_SIZE:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mBATCH_SIZE]))\n\u001b[0;32m---> 31\u001b[0m         results[k, j\u001b[38;5;241m*\u001b[39mBATCH_SIZE:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mBATCH_SIZE] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(exam)\u001b[38;5;241m%\u001b[39mBATCH_SIZE \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,MAX\u001b[38;5;241m-\u001b[39mMIN):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc \n",
    "\n",
    "unique_ids = all_ids.StudyInstanceUID.unique()\n",
    "\n",
    "IMG_TYPE = MASKED\n",
    "IMAGE_PATH = '/home/shared/test/imgs/'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "MIN=0\n",
    "MAX=10\n",
    "\n",
    "for i in range(0,len(unique_ids)):\n",
    "    exam_id = unique_ids[i]\n",
    "    exam = all_ids[all_ids.StudyInstanceUID == exam_id]\n",
    "    exam = exam.sort_values(by='ycoord')\n",
    "    exam_generator = DataSliceGenerator(exam, IMAGE_PATH, img_type = IMG_TYPE,\n",
    "                                        verbose=False, n_channels=1, \n",
    "                                        set_type='test', batch_size=1,\n",
    "                                        shuffle=False, dim=386)\n",
    "    \n",
    "    x_test = np.zeros([len(exam),386,386,1])\n",
    "    for j in range(0,len(exam)):\n",
    "        x_test[j],_ = exam_generator.__getitem__(j)\n",
    "           \n",
    "    feats = np.zeros([MAX-MIN, len(exam),64])\n",
    "    results = np.zeros([MAX-MIN,len(exam),1])\n",
    "    for j in range(int(len(exam)/BATCH_SIZE)):\n",
    "        for k in range(0,MAX-MIN):\n",
    "            feats[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(model_partials[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "            results[k, j*BATCH_SIZE:(j+1)*BATCH_SIZE] = np.array(models[k](x_test[j*BATCH_SIZE:(j+1)*BATCH_SIZE]))\n",
    "    if len(exam)%BATCH_SIZE != 0:\n",
    "        for k in range(0,MAX-MIN):\n",
    "            feats[k, (j+1)*BATCH_SIZE:] = np.array(model_partials[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "            results[k, (j+1)*BATCH_SIZE:] = np.array(models[k](x_test[(j+1)*BATCH_SIZE:]))\n",
    "        \n",
    "    for k in range(MIN,MAX):\n",
    "        exam['features'] = feats[k-MIN].tolist()\n",
    "        exam['preds'] = results[k-MIN].tolist()\n",
    "        np.save('/home/shared/test/turku_0'+ str(k)+ '/' + exam_id, exam.to_dict(orient='records'))\n",
    "\n",
    "    if i %10 == 0:\n",
    "        print(i, 'time is: ', datetime.datetime.now())\n",
    "        gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
