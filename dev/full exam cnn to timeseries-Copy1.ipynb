{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd115d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n",
      "2.8.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import filters\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential \n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Conv2D, MultiHeadAttention, AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D , Conv3D, Layer, MaxPooling2D, Dropout, Flatten, Dense, GRU, ConvLSTM2D, Input, BatchNormalization, TimeDistributed, MaxPooling3D, Bidirectional, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from random import shuffle\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# from tensorflow_docs.vis import embed\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "\n",
    "# import cv2\n",
    "# import imageio\n",
    "# import cv2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import IPython\n",
    "# from six.moves import urllib\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "import pydicom\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "# import bisect\n",
    "np.random.seed(1234)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "MAX_SEQ_LENGTH = 200\n",
    "NUM_FEATURES = 1024\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 2\n",
    "image_path = \"/home/data/rsna-str-pulmonary-embolism-detection/train\"\n",
    "NUM_SCANS = 8\n",
    "NUM_CHANNELS = 1\n",
    "INPUT_DIM = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f815d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "used_ids = np.load('/home/shared/nps/all_scans/convnext/ids.npy')\n",
    "used_ids = used_ids.tolist()\n",
    "for i in range(0, int(len(used_ids)/256)+1):\n",
    "    features = np.load('/home/shared/nps/all_scans/convnext/features'+str(i)+'.npy')\n",
    "    labels = np.load('/home/shared/nps/all_scans/convnext/label'+str(i)+'.npy')\n",
    "    for j in range(len(features)):\n",
    "        xs.append(features[j])\n",
    "        ys.append(labels[j])\n",
    "xs = xs[:len(used_ids)]\n",
    "ys = ys[:len(used_ids)]\n",
    "# np.shape(train_x), np.shape(train_y)\n",
    "# train_vals = pd.DataFrame({'StudyInstanceUID':used_ids,'X': train_x,'Y':train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2278d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_ids = np.array(used_ids)\n",
    "all_ids = pd.DataFrame({'StudyInstanceUID':used_ids[:,0], 'SeriesInstanceUID':used_ids[:,1],\n",
    "                       'SOPInstanceUID':used_ids[:,2], 'features':xs, 'pe_present_on_slab':ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1bf7439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3662786/1213750063.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ids = pd.read_csv('all_ids_updated.csv')\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv('all_ids_updated.csv')\n",
    "train_ids = pd.read_csv('train_df_upd.csv').drop(columns='Unnamed: 0')\n",
    "test_ids = pd.read_csv('test_df_upd.csv').drop(columns='Unnamed: 0')\n",
    "val_ids = pd.read_csv('val_df_upd.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8e3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = pd.merge(ids, all_ids, 'left')\n",
    "all_ids = all_ids.dropna()\n",
    "all_ids.ycoord = all_ids.ycoord.replace('True', '1.0').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994c2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = all_ids[all_ids.StudyInstanceUID.isin(train_ids.StudyInstanceUID)]\n",
    "test_df = all_ids[all_ids.StudyInstanceUID.isin(test_ids.StudyInstanceUID)]\n",
    "val_df = all_ids[all_ids.StudyInstanceUID.isin(val_ids.StudyInstanceUID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb24262",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_ids[train_ids.StudyInstanceUID.isin(train_df.StudyInstanceUID)]\n",
    "test_ids = test_ids[test_ids.StudyInstanceUID.isin(test_df.StudyInstanceUID)]\n",
    "val_ids = val_ids[val_ids.StudyInstanceUID.isin(val_df.StudyInstanceUID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1796445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids_pos = val_ids[val_ids.negative_exam_for_pe == False]\n",
    "val_ids_neg = val_ids[val_ids.negative_exam_for_pe == True].sample(n=len(val_ids_pos))\n",
    "\n",
    "train_ids_pos = train_ids[train_ids.negative_exam_for_pe == False]\n",
    "train_ids_neg = train_ids[train_ids.negative_exam_for_pe == True].sample(n=len(train_ids_pos))\n",
    "\n",
    "val_ids_sample = pd.concat([val_ids_neg, val_ids_pos])\n",
    "train_ids_sample = pd.concat([train_ids_neg, train_ids_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32a49af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 5321\n",
      "Total videos for validation: 672\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total videos for training: {len(train_ids)}\")\n",
    "print(f\"Total videos for validation: {len(val_ids)}\")\n",
    "\n",
    "num_features = 512\n",
    "MAX_SEQ_LENGTH = 200\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\n",
    "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_IDs, study_ids, features, num_features,\n",
    "                 seq_length, return_type = 'both', to_fit=True, batch_size=32, \n",
    "                 shuffle=True, resample=False, full_set = None):\n",
    "\n",
    "        self.list_IDs = list_IDs\n",
    "        self.study_ids = study_ids\n",
    "        self.features = features\n",
    "        self.to_fit = to_fit\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_features = num_features\n",
    "        self.seq_length = seq_length\n",
    "        self.resample = resample\n",
    "        self.full_set = full_set\n",
    "        self.return_type = return_type\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "#         print('starting')\n",
    "        indexes = self.list_IDs[index * self.batch_size:((index+1) * self.batch_size)]\n",
    "        X = np.zeros([self.batch_size, self.seq_length, self.num_features])\n",
    "        y_seq = np.zeros([self.batch_size, self.seq_length, 1])\n",
    "        y_tot = np.zeros([self.batch_size, 1])\n",
    "        for i in range(0,self.batch_size):\n",
    "            x, y = self._get_scan_data(self.study_ids.iloc[indexes[i]].StudyInstanceUID)\n",
    "            X[i] = x\n",
    "            y_seq[i] = y[0]\n",
    "            y_tot[i] = y[1]\n",
    "            \n",
    "        if self.to_fit:\n",
    "            if self.return_type =='both':\n",
    "                return (X, [y_seq, y_tot])\n",
    "            elif self.return_type == 'seq':\n",
    "                return (X, y_seq)\n",
    "            elif self.return_type == 'tot':\n",
    "                return (X, y_tot)\n",
    "            else:\n",
    "                print('valid return types are both, seq and tot')\n",
    "                return False\n",
    "        else:\n",
    "            return (X)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        if self.resample == True:\n",
    "            sample_pos = self.full_set[self.full_set.negative_exam_for_pe == False]\n",
    "            sample_neg = self.full_set[self.full_set.negative_exam_for_pe == True].sample(n=len(sample_pos))\n",
    "            self.study_ids = pd.concat([sample_pos, sample_neg]).sample(frac = 1).reset_index(drop=True)\n",
    "        \n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.list_IDs)\n",
    "            \n",
    "    def _get_scan_data(self, study_id):\n",
    "        scan = self.features[self.features.StudyInstanceUID == study_id]\n",
    "        scan = scan[scan.SeriesInstanceUID == scan.iloc[0].SeriesInstanceUID]\n",
    "        scan = scan.sort_values(by=['ycoord'])\n",
    "        \n",
    "        features = scan.features.tolist()\n",
    "        seq = scan.pe_present_on_slab.tolist()\n",
    "        seq = np.array(seq) > 1\n",
    "        tot = scan.negative_exam_for_pe.iloc[0]\n",
    "        \n",
    "        if len(features)>=self.seq_length:\n",
    "            inst = np.round(np.linspace(0,len(features)-1,self.seq_length)).astype(int)\n",
    "            xs = (np.array(features)[inst]).tolist()\n",
    "            ys = seq[inst]\n",
    "        else:\n",
    "            xs = np.zeros([self.seq_length, self.num_features])\n",
    "            ys = np.zeros([self.seq_length, 1])\n",
    "            \n",
    "            xs[:len(features)] = features\n",
    "            ys[:len(features)] = seq\n",
    "        \n",
    "        ys = ys.tolist()\n",
    "        \n",
    "        return (xs, [ys, tot])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_generator = DataGenerator(np.arange(0,len(train_ids_sample)), train_ids_sample,train_df, num_features, MAX_SEQ_LENGTH, resample=True, full_set=train_ids, batch_size = 2)\n",
    "validation_generator = DataGenerator(np.arange(0,len(val_ids_sample)), val_ids_sample,val_df, num_features, MAX_SEQ_LENGTH, batch_size = 2)\n",
    "test_generator = DataGenerator(np.arange(0,len(test_ids)), test_ids, num_features, test_df, MAX_SEQ_LENGTH, batch_size = 2)\n",
    "\n",
    "# x,y = training_generator.__getitem__(0)\n",
    "# np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fd3c9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 200, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 200, 256)     493056      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 200, 256)    65984       ['bidirectional[0][0]',          \n",
      " dAttention)                                                      'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 200, 64)     16448       ['multi_head_attention[0][0]']   \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 200, 64)     0           ['time_distributed[0][0]']       \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 32)           9408        ['time_distributed_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           528         ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 16)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            17          ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 585,441\n",
      "Trainable params: 585,441\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "3483/3484 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.4930\n",
      "Epoch 1: val_loss improved from inf to 0.69310, saving model to /home/shared/model_checkpoint_paige/scan/attention_gru4\n",
      "3484/3484 [==============================] - 381s 108ms/step - loss: 0.6937 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "2817/3484 [=======================>......] - ETA: 1:10 - loss: 0.6933 - accuracy: 0.5069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 14:48:33.201512: W tensorflow/core/framework/op_kernel.cc:1733] INVALID_ARGUMENT: ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/tmp/ipykernel_3662786/1552856302.py\", line 49, in __getitem__\n",
      "    x, y = self._get_scan_data(self.study_ids.iloc[indexes[i]].StudyInstanceUID)\n",
      "\n",
      "  File \"/tmp/ipykernel_3662786/1552856302.py\", line 96, in _get_scan_data\n",
      "    xs[:len(features)] = features\n",
      "\n",
      "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\nTraceback (most recent call last):\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_3662786/1552856302.py\", line 49, in __getitem__\n    x, y = self._get_scan_data(self.study_ids.iloc[indexes[i]].StudyInstanceUID)\n\n  File \"/tmp/ipykernel_3662786/1552856302.py\", line 96, in _get_scan_data\n    xs[:len(features)] = features\n\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[model/bidirectional/forward_gru/Shape/_2]]\n  (1) INVALID_ARGUMENT:  ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\nTraceback (most recent call last):\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_3662786/1552856302.py\", line 49, in __getitem__\n    x, y = self._get_scan_data(self.study_ids.iloc[indexes[i]].StudyInstanceUID)\n\n  File \"/tmp/ipykernel_3662786/1552856302.py\", line 96, in _get_scan_data\n    xs[:len(features)] = features\n\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_82586]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 61\u001b[0m\n\u001b[1;32m     56\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/shared/model_checkpoint_paige/scan/attention_gru4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     57\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     58\u001b[0m     checkpoint_filepath, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 61\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;43;03m#     validation_split = 0.15\u001b[39;49;00m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\nTraceback (most recent call last):\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_3662786/1552856302.py\", line 49, in __getitem__\n    x, y = self._get_scan_data(self.study_ids.iloc[indexes[i]].StudyInstanceUID)\n\n  File \"/tmp/ipykernel_3662786/1552856302.py\", line 96, in _get_scan_data\n    xs[:len(features)] = features\n\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[model/bidirectional/forward_gru/Shape/_2]]\n  (1) INVALID_ARGUMENT:  ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\nTraceback (most recent call last):\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/jupyter-paige/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_3662786/1552856302.py\", line 49, in __getitem__\n    x, y = self._get_scan_data(self.study_ids.iloc[indexes[i]].StudyInstanceUID)\n\n  File \"/tmp/ipykernel_3662786/1552856302.py\", line 96, in _get_scan_data\n    xs[:len(features)] = features\n\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (153,) + inhomogeneous part.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_82586]"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import datetime\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "def get_gru_model():\n",
    "    sequence_length = MAX_SEQ_LENGTH\n",
    "    features_dim = 512\n",
    "    gru_dim = 128\n",
    "    embed_dim = gru_dim*2\n",
    "    dense_dim = 8\n",
    "    num_heads = 4\n",
    "    classes = 1\n",
    "    \n",
    "    inputs = keras.Input(shape=(sequence_length, features_dim))\n",
    "    \n",
    "    x = Bidirectional(keras.layers.GRU(gru_dim, return_sequences=True))(inputs)\n",
    "#     x = MultiHeadAttention(num_heads=4, key_dim=32, dropout=0.6)(x,x)\n",
    "\n",
    "#     x = TimeDistributed(layers.Dense(64, activation='relu'))(x)\n",
    "#     x = TimeDistributed(keras.layers.Dropout(0.5))(x)\n",
    "    \n",
    "#     x = PositionalEmbedding(\n",
    "#         sequence_length, embed_dim, name=\"frame_position_embedding\")(x)\n",
    "#     x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
    "        \n",
    "    x = MultiHeadAttention(num_heads=2, key_dim=32, dropout=0.4)(x,x)\n",
    "#     x = TimeDistributed(layers.Dense(64, activation='relu'))(x)\n",
    "#     x = TimeDistributed(keras.layers.Dropout(0.5))(x)\n",
    "    \n",
    "    x = TimeDistributed(layers.Dense(64, activation='relu'))(x)\n",
    "    x = TimeDistributed(keras.layers.Dropout(0.4))(x)\n",
    "    \n",
    "    x = keras.layers.GRU(32, dropout=0.4)(x)\n",
    "    \n",
    "#     x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "#     x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.8)(x)\n",
    "    output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    rnn_model = keras.Model(inputs, output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "#         optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01),\n",
    "        loss=\"binary_crossentropy\", \n",
    "        metrics=[\"accuracy\",]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "model = get_gru_model()\n",
    "model.summary()\n",
    "\n",
    "checkpoint_filepath = '/home/shared/model_checkpoint_paige/scan/attention_gru4'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data = validation_generator,\n",
    "    epochs=30,\n",
    "    batch_size = 1,\n",
    "#     validation_split = 0.15\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7fe7875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 200, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 200, 128)     221952      ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 200, 32)     4128        ['bidirectional[0][0]']          \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 200, 32)     0           ['time_distributed[0][0]']       \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 200, 16)      2400        ['time_distributed_1[0][0]']     \n",
      "                                                                                                  \n",
      " multi_head_attention_30 (Multi  (None, 200, 16)     4304        ['gru_1[0][0]',                  \n",
      " HeadAttention)                                                   'gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 16)          0           ['multi_head_attention_30[0][0]']\n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dropout_66 (Dropout)           (None, 16)           0           ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            17          ['dropout_66[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 232,801\n",
      "Trainable params: 232,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      " 898/3484 [======>.......................] - ETA: 4:32 - loss: 0.6967 - accuracy: 0.4911"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 42\u001b[0m\n\u001b[1;32m     37\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/shared/model_checkpoint_paige/scan/attention_gru7\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     39\u001b[0m     checkpoint_filepath, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;43;03m#     validation_split = 0.15\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_gru_model():\n",
    "    sequence_length = MAX_SEQ_LENGTH\n",
    "    features_dim = 512\n",
    "    gru_dim = 64\n",
    "    embed_dim = gru_dim*2\n",
    "    dense_dim = 8\n",
    "    num_heads = 4\n",
    "    classes = 1\n",
    "    \n",
    "    inputs = keras.Input(shape=(sequence_length, features_dim))\n",
    "    \n",
    "    x = Bidirectional(keras.layers.GRU(gru_dim, return_sequences=True))(inputs)\n",
    "    x = TimeDistributed(layers.Dense(32, activation='relu'))(x)\n",
    "    x = TimeDistributed(keras.layers.Dropout(0.6))(x)   \n",
    "    x = keras.layers.GRU(int(gru_dim/4), dropout=0.4, return_sequences=True)(x)\n",
    "    x = MultiHeadAttention(num_heads=2, key_dim=32, dropout=0.4)(x,x)\n",
    "    x = keras.layers.GlobalMaxPooling1D()(x)\n",
    "#     x = keras.layers.Dropout(0.6)(x)\n",
    "#     x = keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.9)(x)\n",
    "    output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    rnn_model = keras.Model(inputs, output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "#         optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01),\n",
    "        loss=\"binary_crossentropy\", \n",
    "        metrics=[\"accuracy\",]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "model = get_gru_model()\n",
    "model.summary()\n",
    "\n",
    "checkpoint_filepath = '/home/shared/model_checkpoint_paige/scan/attention_gru7'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data = validation_generator,\n",
    "    epochs=10,\n",
    "    batch_size = 1,\n",
    "#     validation_split = 0.15\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1c54eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turku_lstm(seq_len, dim):\n",
    "        inputs = keras.Input(shape=(seq_len, dim))\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.Bidirectional(layers.LSTM(units=64, return_sequences=True))(x)\n",
    "        x = layers.TimeDistributed(layers.Dense(128, activation='relu'))(x)\n",
    "        x = layers.TimeDistributed(layers.Dense(32, activation='relu'))(x)\n",
    "        slice_outputs = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)\n",
    "        \n",
    "        reshaped_features = layers.Reshape((seq_len,))(slice_outputs)\n",
    "#         reshaped_features = layers.Dropout(0.05)(reshaped_features)\n",
    "        stack_outputs = layers.Dense(1, activation='sigmoid', name='sequence')(reshaped_features)\n",
    "        \n",
    "        model = keras.models.Model(inputs=inputs, outputs=[slice_outputs, stack_outputs])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "831863e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids_sample = train_ids_sample.sample(frac=1)\n",
    "\n",
    "training_generator = DataGenerator(np.arange(0,len(train_ids_sample)), \n",
    "                                   train_ids_sample,\n",
    "                                   train_df, \n",
    "                                   num_features, \n",
    "                                   200, \n",
    "                                   resample=True, \n",
    "                                   full_set=train_ids, \n",
    "                                   return_type='tot',\n",
    "                                   batch_size = 1)\n",
    "validation_generator = DataGenerator(np.arange(0,len(val_ids_sample)), \n",
    "                                     val_ids_sample,\n",
    "                                     val_df, \n",
    "                                     num_features, \n",
    "                                     200,\n",
    "                                     return_type='tot',\n",
    "                                     batch_size = 1)\n",
    "test_generator = DataGenerator(np.arange(0,len(test_ids)), \n",
    "                               test_ids, \n",
    "                               num_features, \n",
    "                               test_df, \n",
    "                               200, \n",
    "                               return_type='tot',\n",
    "                               batch_size = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7eff03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 200, 512)]        0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 200, 512)         2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirecti  (None, 200, 128)         295424    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_51 (TimeDi  (None, 200, 128)         16512     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_52 (TimeDi  (None, 200, 32)          4128      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_53 (TimeDi  (None, 200, 1)           33        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " reshape_16 (Reshape)        (None, 200)               0         \n",
      "                                                                 \n",
      " sequence (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 318,346\n",
      "Trainable params: 317,322\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "3483/3484 [============================>.] - ETA: 0s - loss: 0.9714 - time_distributed_53_loss: 0.2774 - sequence_loss: 0.6940 - time_distributed_53_accuracy: 0.8945 - sequence_accuracy: 0.5108\n",
      "Epoch 1: val_loss improved from inf to 0.96607, saving model to /home/shared/model_checkpoint_paige/scan/turku\n",
      "3484/3484 [==============================] - 380s 108ms/step - loss: 0.9715 - time_distributed_53_loss: 0.2774 - sequence_loss: 0.6940 - time_distributed_53_accuracy: 0.8945 - sequence_accuracy: 0.5109 - val_loss: 0.9661 - val_time_distributed_53_loss: 0.2798 - val_sequence_loss: 0.6863 - val_time_distributed_53_accuracy: 0.8913 - val_sequence_accuracy: 0.5645\n",
      "Epoch 2/10\n",
      "2950/3484 [========================>.....] - ETA: 56s - loss: 0.9443 - time_distributed_53_loss: 0.2634 - sequence_loss: 0.6809 - time_distributed_53_accuracy: 0.8946 - sequence_accuracy: 0.5729"
     ]
    }
   ],
   "source": [
    "model = get_turku_lstm(200,512)\n",
    "model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=\"binary_crossentropy\", \n",
    "        metrics=[\"accuracy\",]\n",
    "    )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "checkpoint_filepath = '/home/shared/model_checkpoint_paige/scan/turku'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data = validation_generator,\n",
    "    epochs=10,\n",
    "    batch_size = 1,\n",
    "#     validation_split = 0.15\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c02b7383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 200, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 200, 512)    1024        ['input_11[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_28 (Multi  (None, 200, 512)    2100736     ['layer_normalization_54[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 200, 512)     0           ['multi_head_attention_28[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_52 (TFOpL  (None, 200, 512)    0           ['dropout_60[0][0]',             \n",
      " ambda)                                                           'input_11[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 200, 512)    1024        ['tf.__operators__.add_52[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 200, 4)       2052        ['layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 200, 4)       0           ['conv1d_52[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 200, 512)     2560        ['dropout_61[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_53 (TFOpL  (None, 200, 512)    0           ['conv1d_53[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_52[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 200, 512)    1024        ['tf.__operators__.add_53[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_29 (Multi  (None, 200, 512)    2100736     ['layer_normalization_56[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 200, 512)     0           ['multi_head_attention_29[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  (None, 200, 512)    0           ['dropout_62[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_53[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 200, 512)    1024        ['tf.__operators__.add_54[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 200, 4)       2052        ['layer_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 200, 4)       0           ['conv1d_54[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 200, 512)     2560        ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_55 (TFOpL  (None, 200, 512)    0           ['conv1d_55[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_54[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 200)         0           ['tf.__operators__.add_55[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          25728       ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            129         ['dropout_64[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,240,649\n",
      "Trainable params: 4,240,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1540/3484 [============>.................] - ETA: 3:24 - loss: 0.7041 - accuracy: 0.4857"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 66\u001b[0m\n\u001b[1;32m     61\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     62\u001b[0m     checkpoint_filepath, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "        input_shape,\n",
    "        head_size,\n",
    "        num_heads,\n",
    "        ff_dim,\n",
    "        num_transformer_blocks,\n",
    "        mlp_units,\n",
    "        dropout=0,\n",
    "        mlp_dropout=0,\n",
    "    ):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "input_shape = [200,512]\n",
    "\n",
    "model = build_model(\n",
    "        input_shape,\n",
    "        head_size=256,\n",
    "        num_heads=4,\n",
    "        ff_dim=4,\n",
    "        num_transformer_blocks=2,\n",
    "        mlp_units=[128],\n",
    "        mlp_dropout=0.4,\n",
    "        dropout=0.25,\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "checkpoint_filepath = '/home/shared/model_checkpoint_paige/scan/transformer'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    ")\n",
    "# callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    training_generator,\n",
    "    validation_data = validation_generator,\n",
    "    epochs=10,\n",
    "    batch_size=1,\n",
    "    callbacks=[checkpoint],\n",
    ")\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7c167284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 3s 13ms/step - loss: 0.6074 - accuracy: 0.7005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6073625683784485, 0.7004950642585754]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath)\n",
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "073f97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.convert_to_tensor(val_vals.X.to_list())\n",
    "y = np.reshape(val_vals.Y.astype('float').to_list(), [405])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2c8c75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a0290b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7012345679012346"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(131+153)/(131+71+50+153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "18aa1249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[131,  71],\n",
       "       [ 50, 153]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# pred = pred - 0.03\n",
    "cm = confusion_matrix(y, pred.round())\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1522c8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7536945812807881"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "153/203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "095ab4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7536945812807881"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1,1]/(cm[1,0]+cm[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ce37b19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7536945812807881, 0.6485148514851485)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = cm[0,0]/(cm[0,0] + cm[0,1])\n",
    "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "specificity, sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0d9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "71b50c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a1c22bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                  estimator_name='example estimator')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
