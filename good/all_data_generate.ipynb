{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd115d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# from glob import glob\n",
    "# from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "# from sklearn.cluster import KMeans\n",
    "from skimage import filters\n",
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras import Model, Sequential \n",
    "# from tensorflow.keras.utils import Sequence\n",
    "# from tensorflow.keras.layers import Conv2D, MultiHeadAttention, AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D , Conv3D, Layer, MaxPooling2D, Dropout, Flatten, Dense, GRU, ConvLSTM2D, Input, BatchNormalization, TimeDistributed, MaxPooling3D, Bidirectional, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from random import shuffle\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "# from keras.models import Model, load_model\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "import pydicom\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(1234)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "MAX_SEQ_LENGTH = 200\n",
    "IMG_SIZE = 512\n",
    "image_path = \"/home/data/pe/test\"\n",
    "NUM_SCANS = 8\n",
    "NUM_CHANNELS = 1\n",
    "INPUT_DIM = 256\n",
    "NUM_FEATURES = num_features = 512\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "LAYER_BACK = 4\n",
    "import cv2\n",
    "import gc\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = pd.read_csv('/home/data/pe/train.csv')\n",
    "all_ids_test = pd.read_csv('/home/data/pe/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39241d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "from keras.layers import Input, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "segment_model = Unet(backbone_name='resnet34', encoder_weights=None, input_shape=(None, None, 1))\n",
    "\n",
    "segment_model.trainable = False\n",
    "\n",
    "segment_model.load_weights('/home/shared/model_checkpoint_paige/segment/segment_lungs')\n",
    "\n",
    "segment_model.compile(\n",
    "    'Adam',\n",
    "    loss=sm.losses.bce_jaccard_loss,\n",
    "    metrics=[sm.metrics.iou_score],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9860e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice_data(slice, verbose = False, dim=256, folder='nps/imgs'):\n",
    "    study_id = slice.StudyInstanceUID\n",
    "    series_id = slice.SeriesInstanceUID\n",
    "    SOP_id = slice.SOPInstanceUID\n",
    "    \n",
    "    try:\n",
    "        data = pydicom.dcmread(os.path.join(image_path, study_id, series_id, SOP_id + '.dcm'))\n",
    "    except:\n",
    "        return 'ERROR'\n",
    "    \n",
    "    ycoord = data.get_item([0x0020, 0x0032])\n",
    "    ycoord = float(str(ycoord.value).split('\\\\')[-1].replace(\"'\",''))\n",
    "    intercept = int(float(data.get_item([0x0028, 0x1052]).value)) \n",
    "    slope = int(float(data.get_item([0x0028, 0x1053]).value))                \n",
    "    frame = np.asarray(data.pixel_array  * slope + intercept)\n",
    "    \n",
    "    if verbose:\n",
    "        fig, ax = plt.subplots(2, 2, figsize=[24, 24])\n",
    "        ax[0][0].imshow(frame)\n",
    "        ax[0][0].axis('off')\n",
    "\n",
    "\n",
    "    frame = frame.reshape((512,512,1)) \n",
    "    original = np.copy(frame)\n",
    "    frame = frame[None, ...]\n",
    "    \n",
    "    frame = tf.convert_to_tensor(frame)\n",
    "    \n",
    "    frame = preprocess_input(frame)\n",
    "    mask = np.round(segment_model(frame) + 0.1)\n",
    "    \n",
    "    masked = mask*frame\n",
    "    masked = masked[0]\n",
    "    \n",
    "    frame = frame[0]\n",
    "    mask = mask[0]\n",
    "\n",
    "    if np.round(mask).sum() > 10000:\n",
    "\n",
    "        if verbose:\n",
    "            ax[0][1].imshow(mask)\n",
    "            ax[0][1].axis('off')\n",
    "\n",
    "\n",
    "        x_min = np.min(tf.where(mask != 0)[:,0])\n",
    "        x_max = np.max(tf.where(mask != 0)[:,0])\n",
    "        y_min = np.min(tf.where(mask != 0)[:,1])\n",
    "        y_max = np.max(tf.where(mask != 0)[:,1])\n",
    "\n",
    "        frame = np.array(frame[x_min:x_max,y_min:y_max]).astype('float32')\n",
    "        masked = np.array(masked[x_min:x_max,y_min:y_max]).astype('float32')\n",
    "        original = np.array(original).astype('float32')\n",
    "\n",
    "        img = np.zeros([dim,dim,3])\n",
    "        img[:,:,0] = cv2.resize(frame,(dim,dim))\n",
    "        img[:,:,1] = cv2.resize(masked,(dim,dim))\n",
    "        img[:,:,2] = cv2.resize(original,(dim,dim))\n",
    "\n",
    "        if verbose:\n",
    "            ax[1][0].imshow(frame)\n",
    "            ax[1][0].axis('off')\n",
    "\n",
    "        img = (np.clip(img,-250, 450)-100)/350\n",
    "\n",
    "        if verbose:\n",
    "            print(np.max(frame), np.min(frame))\n",
    "            print(np.max(img), np.min(img))\n",
    "            ax[1][1].imshow(img[:,:,0])\n",
    "            ax[1][1].axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        id_str = study_id+'_'+series_id+'_'+SOP_id + '.png'\n",
    "        img = (img +1)*(255/2)\n",
    "\n",
    "        cv2.imwrite('/home/shared/' + folder+ + id_str, img)\n",
    "\n",
    "    return ycoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = all_ids.sort_values(by=['StudyInstanceUID','SOPInstanceUID']).reset_index(drop=True)\n",
    "all_ids_test = all_ids_test.sort_values(by=['StudyInstanceUID','SOPInstanceUID']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d68dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids['ycoord'] = all_ids.apply(lambda x: get_slice_data(x), axis=1)\n",
    "all_ids_test['ycoord'] = all_ids_test.apply(lambda x: get_slice_data(x), axis=1, folder='test/imgs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af689b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/shared/nps/imgs/'\n",
    "\n",
    "lisdir = os.listdir(directory)http://172.27.10.122:6831/user/paige/notebooks/all%20data%20generate.ipynb#\n",
    "\n",
    "files = pd.DataFrame({'file_name':lisdir})\n",
    "files = pd.DataFrame(data=files['file_name'].str.replace('.png','').str.split('_').to_list(), columns=['StudyInstanceUID', 'SeriesInstanceUID','SOPInstanceUID'])\n",
    "files['contains_lung'] = True\n",
    "\n",
    "all_ids = pd.merge(all_ids, files, how='outer')\n",
    "all_ids = all_ids.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/shared/test/imgs/'\n",
    "\n",
    "lisdir = os.listdir(directory)\n",
    "\n",
    "files = pd.DataFrame({'file_name':lisdir})\n",
    "files = pd.DataFrame(data=files['file_name'].str.replace('.png','').str.split('_').to_list(), columns=['StudyInstanceUID', 'SeriesInstanceUID','SOPInstanceUID'])\n",
    "files['contains_lung'] = True\n",
    "\n",
    "all_ids_test = pd.merge(all_ids_test, files, how='outer')\n",
    "all_ids_test = all_ids_test.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e324c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids.to_csv('all_ids_updated.csv')\n",
    "all_ids_test.to_csv('test_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_studies = all_ids.drop_duplicates('StudyInstanceUID')\n",
    "all_studies = all_studies.sample(frac=1).reset_index(drop=True)\n",
    "all_studies['fold'] = all_studies.index % 10\n",
    "all_studies = all_studies[['StudyInstanceUID','fold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66829418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_studies.to_csv('fold_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
